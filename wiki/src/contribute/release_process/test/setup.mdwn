[[!meta title="Test suite installation and setup"]]

Here's how to set up an environment to run our automated test suite.
Alternatively, you way want to use the `tails::tester` class from the
[[!tails_gitweb_repo puppet-tails]] Puppet module.

Once you have a working environment, see [[test/usage]].

[[!toc levels=2]]

Operating system
================

<div class="note">
<p>
<b>For Wayland users:</b> at the moment the <tt>--view</tt> and
<tt>--vnc-server-only</tt> options only work on X11.
</p>
</div>

If you usually run another operating system than Debian
Buster, Bullseye or Sid, then you need to:

1. Enable nested virtualization on your host system.

   For example, if the host system has an Intel CPU:

         if [ "$(cat /sys/module/kvm_intel/parameters/nested)" != Y ]; then
            echo "options kvm_intel nested=Y" | \
                 sudo tee /etc/modprobe.d/kvm.conf
         fi

2. Prepare a Debian virtual machine; we recommend the stable release,
   Debian Buster.

3. And then, every step below applies to this virtual machine, instead
   of to the host system.

Install dependencies
====================

To install the dependencies on our test suite:

1. Enable the `non-free` APT component.

2. Install the following packages:

        dist=$(lsb_release --short --codename)
        if [ "${dist}" = buster ]; then
            echo 'deb http://ftp.us.debian.org/debian/ buster-backports main' \
                | sudo tee /etc/apt/sources.list.d/buster-backports.list
            echo -e "Package: qemu*\nPin: release n=buster-backports, o=Debian Backports\nPin-Priority: 990" \
                | sudo tee /etc/apt/preferences.d/qemu
        fi
        sudo apt update && \
        sudo apt install \
            cucumber \
            devscripts \
            dnsmasq-base \
            gawk \
            git \
            i18nspector \
            imagemagick \
            libcap2-bin \
            libvirt-clients \
            libvirt-daemon-system \
            libvirt-dev \
            libvirt0 \
            obfs4proxy \
            openssh-server \
            ovmf \
            pry \
            python3-potr \
            python3-slixmpp \
            qemu-system-common \
            qemu-system-x86 \
            qemu-utils \
            redir \
            ruby-guestfs \
            ruby-json \
            ruby-libvirt \
            ruby-packetfu \
            ruby-rb-inotify \
            ruby-rspec \
            ruby-test-unit \
            seabios \
            tcpdump \
            tcplay \
            tor \
            unclutter \
            virt-viewer \
            x11vnc \
            tigervnc-viewer \
            x264 \
            xdotool \
            xvfb \
            ffmpeg \
            python3-opencv \
            python3-pil \
            && \
        sudo service libvirtd restart

Other requirements
==================

Synchronized clock
------------------

The system running the test suite needs an accurate clock since we
sync the clock from the host to the Tails guest after a background
snapshot restore to appease Tor.

You might want to enable `systemd-timesyncd.service` or your favorite
time synchronization tool for this.

File permissions
----------------

The user that runs QEMU (via libvirt) needs read-access at least to
the content of `features/misc_files/` in the Git checkout.

AppArmor tweaks
---------------

If you have AppArmor enabled:

* You need to add the `/tmp/TailsToaster/** rwk,` line
  to `/etc/apparmor.d/libvirt/TEMPLATE.qemu`, in the
  `profile LIBVIRT_TEMPLATE` section; then delete
  `/etc/apparmor.d/libvirt/libvirt-*` and restart the test suite.
  If you use a custom `TMPDIR` to run the test suite,
  replace `/tmp/TailsToaster` with the value of that `$TMPDIR`.

Special use cases
=================

Access the system under test with VNC
-------------------------------------

If you're running the test suite in a nested environnement, install
`tigervnc-viewer` on the bare metal level-0 host. Then you can use vncviewer's
`-via` option so that it automatically setup a ssh tunnel to your first level
test suite domain for you and display the Tails VM. E.g.
where `$DISPLAY` is the display given to you by `run_test_suite` (often 0):

    vncviewer -viewonly -via user@level0 localhost:$DISPLAY
